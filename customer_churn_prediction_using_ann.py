# -*- coding: utf-8 -*-
"""Customer_Churn_Prediction_using_ANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15nqyVtk2O4NshWOS90CWmipwXcTrdzLA
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# for Scaling Purpose:
from sklearn.preprocessing import StandardScaler
# for train-test split we import module that we require:
from sklearn.model_selection import train_test_split

dataset = pd.read_csv("/Churn_Modelling_MLP.csv")

dataset.head(3)

dataset.isnull().sum()

input_data  = dataset.iloc[:,:-1]
output_data = dataset.iloc[:,-1]



# Scaling:
ss = StandardScaler()
# making it into Dataframe:
input_data = pd.  DataFrame(ss.fit_transform(input_data),columns=input_data.columns)

# In Deep Learning we mostly use scaling data, do not consider data that can't scale:

input_data



input_data.shape

# after ann compile we also have to split data into training & testing:
# 4 variables i/p =input_data, o/p =output_data, testing =20 % as 0.2 and random_state is 42:
x_train,x_test,y_train,y_test = train_test_split(input_data,output_data,test_size=0.2,random_state=42)

# train data size:
x_train.shape

x_test.head(3) # for checking on new data after prediction

# Now we have to create a Neural Network for this we want Tenserflow & Keras:
import tensorflow

from keras.layers import Dense
from keras.models import Sequential

ann = Sequential()

# How many nodes we want in hidden layers:

# For 1st hidden Layer hierarchical pattern we use 6 for 8 columns/node
#for input-dimension is 8
#activation function is =reLU

# For 2nd layer 4 node ,for 3rd layer 2 node, for 4th node 1 layer as we want single output:
# input dumension are given by only 1st time:
#

# hidden layer: 1, 2, 3, 4:
ann.add(Dense(6,input_dim=8,activation="relu"))
ann.add(Dense(4,activation="relu"))
ann.add(Dense(2,activation="relu"))
ann.add(Dense(1,activation="sigmoid"))

# compiling model using optimizer 'adam' which is best one for the optimization and many more is there
ann.compile(optimizer="adam",loss="binary_crossentropy",metrics=["accuracy"])

# fitting our ann network:
# use our 4 variables of train test split:
# for batch size we check how much data in training , in this case it is (8000,8).
# epochs/iteration:
ann.fit(x_train, y_train, batch_size=100,epochs= 50)







"""**accuracy check for y train by x_train:**"""

prd1 = ann.predict(x_train)

prd_data1 = []
for i in prd1:
  if i[0] >0.5:
    prd_data1.append(1)
  else:
    prd_data1.append(0)

"""**for accuracy score we check this data:**"""

# for getting predicted value of y we use prediction of x_test:
# for first time accuracy check with sklearn this output is in the form of Numbers not in (0 or 1) as we want

prd = ann.predict(x_test)

prd_data = []
for i in prd:
  if i[0] >0.5:
    prd_data.append(1)
  else:
    prd_data.append(0)

#prd_data



from sklearn.metrics import accuracy_score

# testing accuracy we get: 84.3 %
accuracy_score(y_test,prd_data)*100

# training accuracy we get:84.05
# again we have to do same work as we do for y_test
# get prd_data1 for y_train from x_test
accuracy_score(y_train,prd_data1)*100

# update epoch from 10 to 50 we solve the prolbem of overfitting here with approximate same train & testing output:
# 85.675 & 85.15

"""**Checking on new Data**"""

# first time we get an error beacuse we have list and our ann with keras and ternserflow is wroking with numpy
# So we convert that list to  numpy's array: and error is solved:

# **Checking on new Data**
prd = ann.predict(np.array([[-0.564197, -0.660018, -0.695982, 0.324119, 0.807737, -1.547768, -1.030670, -1.013811]]))
prd_data = []
for i in prd:
  if i[0] >0.5:
    prd_data.append(1)
  else:
    prd_data.append(0)
print(prd_data)

#output on new data check is :  0

y_test.head(3)

# output for 1 st value as we check, where prd|_data from x_test = y_test: both have answer: Zero(0)

"""# So by this Checking we can say that our ANN network we made is built very properly and It will help to predict correct output."""

